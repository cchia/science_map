{
    "id": "shannon_entropy_1948",
    "personId": "claude_shannon",
    "title": "å‘è¡¨ã€Šé€šä¿¡çš„æ•°å­¦ç†è®ºã€‹ (ä¿¡æ¯ç†µ)",
    "title_en": "Publishes 'A Mathematical Theory of Communication' (Information Entropy)",
    "year": 1948,
    "lat": 40.7357,
    "lng": -74.0036,
    "city": "çº½çº¦ / é»˜é‡Œå±± (è´å°”å®éªŒå®¤)",
    "city_en": "New York / Murray Hill (Bell Labs)",
    "country": "ç¾å›½",
    "country_en": "United States",
    "storyline_ids": ["thermo_story"],
    "field": ["æ•°å­¦", "å·¥ç¨‹å­¦", "è®¡ç®—æœº"],
    "field_en": ["Mathematics", "Engineering", "Computer Science"],
    
    "media": {
      "event_image": "assets/images/information_theory.jpg",
      "video": {
        "url": "https://www.youtube.com/watch?v=X40ft1Lt1f0",
        "title": "ä¿¡æ¯è®ºï¼šä»€ä¹ˆæ˜¯æ¯”ç‰¹ï¼Ÿ",
        "title_en": "Information Theory: What is a Bit?",
        "duration": "9:52"
      }
    },
    
    "summary": {
      "text": "å…‹åŠ³å¾·Â·é¦™å†œï¼ˆClaude Shannonï¼‰åœ¨è´å°”å®éªŒå®¤å‘è¡¨äº†ä¸€ç¯‡è¢«èª‰ä¸ºâ€œä¿¡æ¯æ—¶ä»£å¤§å®ªç« â€çš„è®ºæ–‡ã€‚ä»–å»ºç«‹äº†ä¸€å¥—å…¨æ–°çš„æ•°å­¦æ¡†æ¶ï¼Œå°†â€œä¿¡æ¯â€å®šä¹‰ä¸ºä¸€ä¸ªå¯ä»¥é‡åŒ–çš„ç‰©ç†é‡ï¼Œå¹¶å¼•å…¥äº†â€œæ¯”ç‰¹â€(bit) ä½œä¸ºå…¶åŸºæœ¬å•ä½ã€‚ä»–å€Ÿç”¨äº†çƒ­åŠ›å­¦ä¸­â€œç†µâ€çš„æ¦‚å¿µï¼Œæå‡ºäº†â€œä¿¡æ¯ç†µâ€(Information Entropy)ï¼Œç”¨æ¥è¡¡é‡ä¸€æ¡æ¶ˆæ¯ä¸­çš„â€œä¸ç¡®å®šæ€§â€æˆ–â€œä¿¡æ¯é‡â€ã€‚ä»–è¯æ˜äº†æ•°æ®å‹ç¼©çš„æé™ï¼ˆä¿¡æºç¼–ç å®šç†ï¼‰å’Œåœ¨å™ªå£°ä¿¡é“ä¸­æ— è¯¯ä¼ è¾“çš„æœ€å¤§é€Ÿåº¦ï¼ˆä¿¡é“ç¼–ç å®šç†ï¼‰ã€‚",
      "text_en": "Claude Shannon published a paper at Bell Labs often called the 'Magna Carta of the Information Age'. He established a new mathematical framework that defined 'information' as a quantifiable physical quantity and introduced the 'bit' as its fundamental unit. Borrowing from thermodynamics, he proposed 'Information Entropy' to measure the 'uncertainty' or 'information content' of a message. He proved the limits of data compression (Source Coding Theorem) and the maximum speed of error-free transmission over a noisy channel (Channel Coding Theorem).",
      "key_points": [
        "åˆ›ç«‹äº†â€œä¿¡æ¯è®ºâ€(Information Theory)",
        "å®šä¹‰äº†â€œæ¯”ç‰¹â€(bit) ä¸ºä¿¡æ¯å•ä½",
        "æå‡ºäº†â€œä¿¡æ¯ç†µâ€(Entropy) å…¬å¼ï¼šH = -Î£ p log p",
        "å°†â€œé€šä¿¡â€ä»æ¨¡æ‹Ÿå·¥ç¨‹è½¬å˜ä¸ºæ•°å­—æ•°å­¦",
        "è¯æ˜äº†åœ¨å™ªå£°ä¸­è¿›è¡Œå®Œç¾é€šä¿¡æ˜¯å¯èƒ½çš„"
      ],
      "key_points_en": [
        "Founded 'Information Theory'",
        "Defined the 'bit' as the unit of information",
        "Proposed the 'Information Entropy' formula: H = -Î£ p log p",
        "Transformed 'communication' from analog engineering to digital mathematics",
        "Proved perfect communication is possible even with noise"
      ]
    },
  
    "story": {
      "text": "åœ¨é¦™å†œä¹‹å‰ï¼Œå·¥ç¨‹å¸ˆä»¬è®¤ä¸ºè¦è®©ä¿¡å·æ›´æ¸…æ™°ï¼ˆæ¶ˆé™¤å™ªå£°ï¼‰ï¼Œå°±å¿…é¡»ç”¨æ›´å¤§çš„åŠŸç‡â€œå¤§å£°å–Šâ€ã€‚é¦™å†œé€šè¿‡æ•°å­¦è¯æ˜è¿™æ˜¯ä¸€ä¸ªé”™è¯¯çš„æ–¹å‘ã€‚ä»–æŒ‡å‡ºï¼Œé€šä¿¡çš„æœ¬è´¨æ˜¯â€œæ¶ˆé™¤ä¸ç¡®å®šæ€§â€ã€‚å¦‚æœæˆ‘å‘Šè¯‰ä½ å¤ªé˜³æ˜å¤©ä¼šå‡èµ·ï¼Œè¿™å‡ ä¹æ²¡æœ‰ä¿¡æ¯é‡ï¼ˆå› ä¸ºæ¦‚ç‡ pâ‰ˆ1ï¼Œç†µâ‰ˆ0ï¼‰ã€‚å¦‚æœæˆ‘å‘Šè¯‰ä½ ä¸­äº†å½©ç¥¨ï¼Œä¿¡æ¯é‡å°±å·¨å¤§ï¼ˆæ¦‚ç‡ pâ‰ˆ0ï¼Œç†µé«˜ï¼‰ã€‚ä»–å€Ÿç”¨äº†ç»å°”å…¹æ›¼ï¼ˆ`boltzmann_statistical_mechanics_1877`ï¼‰çš„ç†µå…¬å¼ï¼Œå› ä¸ºä¿¡æ¯çš„ä¸ç¡®å®šæ€§ä¸çƒ­åŠ›å­¦çš„æ··ä¹±åº¦åœ¨æ•°å­¦ä¸ŠæƒŠäººåœ°ç›¸ä¼¼ã€‚æ®è¯´ï¼Œæ˜¯å†¯Â·è¯ºä¾æ›¼å»ºè®®ä»–ä½¿ç”¨â€œç†µâ€è¿™ä¸ªè¯çš„ï¼Œç†ç”±æ˜¯ï¼šâ€œæ²¡äººçœŸæ­£æ‡‚ç†µæ˜¯ä»€ä¹ˆï¼Œæ‰€ä»¥åœ¨è¾©è®ºä¸­ä½ ä¼šå ä¸Šé£ã€‚â€",
      "text_en": "Before Shannon, engineers thought the only way to clear up a signal (overcome noise) was to 'shout louder' (more power). Shannon proved mathematically this was wrong. He argued that the essence of communication is 'resolving uncertainty'. If I tell you the sun will rise tomorrow, there is almost zero information (probability pâ‰ˆ1, entropyâ‰ˆ0). If I tell you you won the lottery, the information is huge (probability pâ‰ˆ0, high entropy). He borrowed Boltzmann's (`boltzmann_statistical_mechanics_1877`) formula because the math of uncertainty mirrored thermodynamic disorder. Legend has it John von Neumann advised him to use the word 'Entropy' because 'nobody knows what entropy really is, so in a debate you will always have the advantage.'",
      "diagram": "assets/images/shannon_insight.jpg"
    },
  
    "fun_facts": [
      {
        "icon": "ğŸ¤¹",
        "text": "é¦™å†œæ˜¯ä¸€ä¸ªæ€§æ ¼å¤æ€ªçš„å¤©æ‰ã€‚ä»–åœ¨è´å°”å®éªŒå®¤çš„å¤§å…é‡Œéª‘ç‹¬è½®è½¦ï¼Œä¸€è¾¹éª‘ä¸€è¾¹æŠ›çƒæ‚è€ã€‚ä»–è¿˜åˆ¶é€ è¿‡ä¸€ä¸ªâ€œç»ˆææœºå™¨â€(Ultimate Machine)ï¼šæ‰“å¼€å¼€å…³åï¼Œä¸€åªæœºæ¢°æ‰‹ä¼šä¼¸å‡ºæ¥ï¼ŒæŠŠå¼€å…³å…³æ‰ï¼Œç„¶åç¼©å›å»ã€‚",
        "text_en": "Shannon was an eccentric genius. He rode a unicycle down the halls of Bell Labs while juggling balls. He also built an 'Ultimate Machine': a box with a switch. When you flipped it, a mechanical hand came out, turned the switch off, and retreated."
      },
      {
        "icon": "01",
        "text": "â€œBitâ€ï¼ˆæ¯”ç‰¹ï¼‰è¿™ä¸ªè¯å…¶å®æ˜¯æ•°å­¦å®¶çº¦ç¿°Â·å›¾åŸºï¼ˆJohn Tukeyï¼‰åœ¨ä¸€å¼ åˆé¤çº¸å·¾ä¸Šå†™ä¸‹çš„â€œBinary Digitâ€çš„ç¼©å†™ï¼Œä½†é¦™å†œä½¿å…¶é—»åäºä¸–ã€‚",
        "text_en": "The word 'Bit' was actually coined by mathematician John Tukey (short for 'Binary Digit') on a lunch napkin, but Shannon made it famous."
      }
    ],
  
    "simple_explanation": {
      "text": "é¦™å†œé—®ï¼šä¸–ç•Œä¸Šæœ€ç®€å•çš„â€œæ¶ˆæ¯â€æ˜¯ä»€ä¹ˆï¼Ÿ\nç­”æ¡ˆæ˜¯ï¼šæ˜¯/å¦ï¼ˆ1/0ï¼‰ã€‚è¿™å°±æ˜¯1â€œæ¯”ç‰¹â€ã€‚\næ‰€æœ‰çš„ä¹¦ã€éŸ³ä¹ã€å›¾ç‰‡ã€è§†é¢‘ï¼Œæ— è®ºå¤šä¹ˆå¤æ‚ï¼Œæœ€ç»ˆéƒ½å¯ä»¥è¢«åˆ†è§£æˆä¸€é•¿ä¸²çš„â€œæ˜¯/å¦â€é—®é¢˜ã€‚\né¦™å†œæ•™æˆ‘ä»¬å¦‚ä½•æŠŠè¿™äº›â€œæ˜¯/å¦â€æ‰“åŒ…å¾—æ›´ç´§å‡‘ï¼ˆå‹ç¼©ï¼ŒåƒZIPæ–‡ä»¶ï¼‰ï¼Œä»¥åŠå¦‚ä½•ç»™å®ƒä»¬åŠ ä¸Šâ€œä¿æŠ¤å±‚â€ï¼ˆçº é”™ç ï¼‰ï¼Œè¿™æ ·å³ä½¿ç”µè¯çº¿æœ‰æ‚éŸ³ï¼Œå¯¹æ–¹ä¹Ÿèƒ½æ”¶åˆ°å®Œç¾çš„ä¿¡æ¯ã€‚",
      "text_en": "Shannon asked: What is the simplest possible 'message' in the universe?\nAnswer: Yes/No (1/0). That is 1 'bit'.\nAll books, music, photos, and videos, no matter how complex, can ultimately be broken down into a long string of 'Yes/No' questions.\nShannon taught us how to pack these 'Yes/No's' tighter (Compression, like ZIP files) and how to add 'protective layers' (Error Correction) so that even if the phone line is static, the other person receives a perfect message.",
      "diagram": "assets/images/shannon_bit.jpg"
    },
  
    "applications": [
        {
          "icon": "ğŸ—œï¸",
          "title": "æ•°æ®å‹ç¼© (Data Compression)",
          "title_en": "Data Compression",
          "text": "ZIPæ–‡ä»¶ã€MP3éŸ³ä¹ã€JPEGå›¾ç‰‡â€”â€”æ‰€æœ‰è¿™äº›â€œå‹ç¼©â€æŠ€æœ¯éƒ½ç›´æ¥åŸºäºé¦™å†œçš„â€œä¿¡æºç¼–ç å®šç†â€ï¼ˆå»é™¤å†—ä½™ä¿¡æ¯ï¼‰ã€‚",
          "text_en": "ZIP files, MP3 music, JPEG imagesâ€”all these 'compression' technologies are directly based on Shannon's 'Source Coding Theorem' (removing redundancy)."
        },
        {
          "icon": "ğŸ“¶",
          "title": "é€šä¿¡ä¸äº’è”ç½‘",
          "title_en": "Communication & Internet",
          "text": "ä»5Gç½‘ç»œåˆ°æ·±ç©ºæ¢æµ‹å™¨çš„æ•°æ®ä¼ è¾“ï¼Œæ‰€æœ‰ç°ä»£é€šä¿¡ç³»ç»Ÿéƒ½ä½¿ç”¨é¦™å†œå‘æ˜çš„â€œçº é”™ç â€æ¥ä¿è¯æ•°æ®åœ¨å……æ»¡å™ªå£°çš„ä¿¡é“ä¸­ä¸ä¸¢å¤±ã€‚",
          "text_en": "From 5G networks to deep-space probes, all modern communication systems use 'Error Correction Codes' invented by Shannon to ensure data isn't lost in noisy channels."
        },
        {
          "icon": "ğŸ”",
          "title": "å¯†ç å­¦ (Cryptography)",
          "title_en": "Cryptography",
          "text": "é¦™å†œåœ¨äºŒæˆ˜æœŸé—´è¿˜å‘è¡¨äº†å…³äºå¯†ç å­¦çš„æœºå¯†è®ºæ–‡ï¼Œè¯æ˜äº†â€œä¸€æ¬¡æ€§å¯†ç æœ¬â€(One-time pad) æ˜¯å”¯ä¸€åœ¨æ•°å­¦ä¸Šæ— æ³•ç ´è¯‘çš„åŠ å¯†æ–¹å¼ã€‚",
          "text_en": "Shannon also wrote classified papers on cryptography during WWII, proving that the 'One-time pad' is the only mathematically unbreakable encryption."
        }
      ],
  
    "impact": {
      "text": "é¦™å†œæ˜¯â€œæ•°å­—æ—¶ä»£â€çš„å»ºç­‘å¸ˆã€‚åœ¨ä»–ä¹‹å‰ï¼Œé€šä¿¡æ˜¯â€œæ¨¡æ‹Ÿâ€çš„ï¼ˆæ³¢ï¼‰ï¼›åœ¨ä»–ä¹‹åï¼Œé€šä¿¡å˜æˆäº†â€œæ•°å­—â€çš„ï¼ˆæ¯”ç‰¹ï¼‰ã€‚æ²¡æœ‰ä»–çš„ç†è®ºï¼Œæˆ‘ä»¬ä»Šå¤©å°±ä¸ä¼šæœ‰äº’è”ç½‘ã€æ‰‹æœºã€ç¡¬ç›˜æˆ–ä»»ä½•æ•°å­—è®¾å¤‡ã€‚ä»–å•æªåŒ¹é©¬åœ°åˆ›å»ºäº†ä¸€é—¨æ”¯æ’‘ç°ä»£æ–‡æ˜çš„å­¦ç§‘ã€‚",
      "text_en": "Shannon is the architect of the 'Digital Age'. Before him, communication was 'analog' (waves); after him, it was 'digital' (bits). Without his theory, we would have no Internet, no mobile phones, no hard drives, or any digital devices. He single-handedly created the discipline that underpins modern civilization.",
      "stats": [
          {
            "number": "1948",
            "label": "å¹´ (ä¿¡æ¯è®ºè¯ç”Ÿ)",
            "label_en": "Year (Information Theory Born)"
          },
          {
            "number": "0/1",
            "label": "æ¯”ç‰¹ (åŸºæœ¬å•ä½)",
            "label_en": "Bit (Base Unit)"
          }
        ]
    },
  
    "influence_chain": {
      "influenced_by": [
        {
          "id": "leibniz_binary_1703",
          "contribution": "è±å¸ƒå°¼èŒ¨ï¼ˆæä¾›äº†â€œäºŒè¿›åˆ¶â€ç®—æœ¯çš„åŸºç¡€ï¼Œè¿™æ˜¯â€œæ¯”ç‰¹â€çš„æ•°å­¦èµ·æºï¼‰",
          "contribution_en": "Gottfried Leibniz (provided the foundation of 'binary' arithmetic, the mathematical origin of the 'bit')"
        },
        {
          "id": "boltzmann_statistical_mechanics_1877",
          "contribution": "ç»å°”å…¹æ›¼ï¼ˆé¦™å†œç›´æ¥å€Ÿç”¨äº†ä»–çš„â€œç†µâ€å…¬å¼æ¥é‡åŒ–ä¿¡æ¯çš„ä¸ç¡®å®šæ€§ï¼‰",
          "contribution_en": "Ludwig Boltzmann (Shannon directly borrowed his 'entropy' formula to quantify information uncertainty)"
        },
        {
          "id": "boole_logic_1854",
          "contribution": "ä¹”æ²»Â·å¸ƒå°”ï¼ˆé¦™å†œåœ¨ä»–æ—©æœŸçš„ç¡•å£«è®ºæ–‡ä¸­ï¼Œé¦–æ¬¡å°†å¸ƒå°”ä»£æ•°åº”ç”¨äºç”µå­ç”µè·¯è®¾è®¡ï¼‰",
          "contribution_en": "George Boole (In his earlier master's thesis, Shannon first applied Boolean algebra to electronic circuit design)"
        }
      ],
      "influenced": [
        {
          "id": "transistor_invention_1947",
          "contribution": "æ™¶ä½“ç®¡ï¼ˆè™½ç„¶å‡ ä¹åŒæ—¶å‘æ˜ï¼Œä½†æ™¶ä½“ç®¡ä¸ºé¦™å†œçš„ç†è®ºæä¾›äº†å®Œç¾çš„ç‰©ç†ç¡¬ä»¶â€”â€”å¼€å…³ï¼‰",
          "contribution_en": "The Transistor (though invented almost simultaneously, it provided the perfect physical hardwareâ€”switchesâ€”for Shannon's theory)"
        },
        {
          "id": "internet_1969",
          "contribution": "äº’è”ç½‘ï¼ˆæ•´ä¸ªæ•°å­—ç½‘ç»œçš„æ•°æ®åŒ…äº¤æ¢å’Œä¼ è¾“åè®®ï¼Œéƒ½å»ºç«‹åœ¨é¦™å†œçš„ä¿¡æ¯è®ºä¹‹ä¸Šï¼‰",
          "contribution_en": "The Internet (the entire digital network's packet switching and transmission protocols are built on Shannon's Information Theory)"
        }
      ],
      "legacy_text": "å…‹åŠ³å¾·Â·é¦™å†œå‘Šè¯‰æˆ‘ä»¬ï¼Œâ€œä¿¡æ¯â€å°±åƒâ€œèƒ½é‡â€ä¸€æ ·ï¼Œæ˜¯ä¸€ä¸ªå¯ä»¥è¢«æµ‹é‡ã€å‚¨å­˜å’Œä¼ è¾“çš„ç‰©ç†é‡ã€‚",
      "legacy_text_en": "Claude Shannon taught us that 'Information' is a physical quantity, like 'Energy', that can be measured, stored, and transmitted."
    },
  
    "related_concepts": ["ä¿¡æ¯è®º (Information Theory)", "æ¯”ç‰¹ (Bit)", "ç†µ (Entropy)", "æ•°æ®å‹ç¼© (Compression)", "ä¿¡é“å®¹é‡ (Channel Capacity)", "å†—ä½™ (Redundancy)", "å™ªå£° (Noise)", "å¸ƒå°”ä»£æ•°"],
    "related_concepts_en": ["Information Theory", "Bit", "Entropy", "Data Compression", "Channel Capacity", "Redundancy", "Noise", "Boolean Algebra"],
  
    "quiz": {
      "question": "æ ¹æ®å…‹åŠ³å¾·Â·é¦™å†œï¼ˆClaude Shannonï¼‰çš„ç†è®ºï¼Œä¸€æ¡ä¿¡æ¯çš„â€œä¿¡æ¯é‡â€ï¼ˆä¿¡æ¯ç†µï¼‰å–å†³äºä»€ä¹ˆï¼Ÿ",
      "question_en": "According to Claude Shannon's theory, the amount of 'information' (entropy) in a message depends on what?",
      "options": [
        "æ¶ˆæ¯çš„é•¿åº¦ï¼ˆå­—æ•°ï¼‰",
        "æ¶ˆæ¯çš„å«ä¹‰æˆ–é‡è¦æ€§",
        "æ¶ˆæ¯çš„â€œæ„å¤–ç¨‹åº¦â€æˆ–â€œä¸ç¡®å®šæ€§â€ (Surprise / Uncertainty)",
        "å‘é€æ¶ˆæ¯æ‰€éœ€çš„ç”µåŠ›"
      ],
      "options_en": [
        "The length of the message (word count)",
        "The meaning or importance of the message",
        "The degree of 'surprise' or 'uncertainty' of the message",
        "The electricity needed to send it"
      ],
      "answer": 2,
      "explanation": "åœ¨ä¿¡æ¯è®ºä¸­ï¼Œå‘ç”Ÿæ¦‚ç‡è¶Šä½çš„äº‹æƒ…ï¼ˆè¶Šæ„å¤–ï¼‰ï¼ŒåŒ…å«çš„ä¿¡æ¯é‡å°±è¶Šå¤§ã€‚å¦‚æœæˆ‘çŸ¥é“å¤ªé˜³æ˜å¤©ä¼šå‡èµ·ï¼ˆæ¦‚ç‡æé«˜ï¼‰ï¼Œè¿™æ¡æ¶ˆæ¯çš„â€œä¿¡æ¯é‡â€å‡ ä¹ä¸ºé›¶ã€‚å¦‚æœæˆ‘å‘Šè¯‰ä½ æ˜å¤©ä¼šä¸‹é’è›™é›¨ï¼ˆæ¦‚ç‡æä½ï¼‰ï¼Œè¿™æ¡æ¶ˆæ¯çš„â€œä¿¡æ¯é‡â€å°±å·¨å¤§ã€‚",
      "explanation_en": "In Information Theory, the lower the probability of an event (the more surprising it is), the more information it contains. Knowing the sun will rise (high probability) contains almost zero information. Knowing it will rain frogs (low probability) contains massive information."
    }
  }